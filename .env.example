# Cognee Memory Environment Configuration
# Copy this file to .env and fill in your values

# ===================
# Required: OpenAI API Key
# ===================
OPENAI_API_KEY=sk-your-openai-api-key-here

# ===================
# Optional: LLM Configuration
# ===================
# LLM_PROVIDER=openai
# LLM_MODEL=gpt-4o-mini
# LLM_API_KEY=${OPENAI_API_KEY}

# ===================
# Graph Database (Neo4j)
# ===================
# These are pre-configured for Docker setup
GRAPH_DATABASE_PROVIDER=neo4j
GRAPH_DATABASE_URL=bolt://localhost:7688
GRAPH_DATABASE_USERNAME=neo4j
GRAPH_DATABASE_PASSWORD=cogneepassword

# ===================
# Vector Database (LanceDB)
# ===================
# LanceDB is used for vector storage (file-based, no external service needed)
VECTOR_DB_PROVIDER=lancedb

# ===================
# Optional: Embedding Model
# ===================
# EMBEDDING_PROVIDER=openai
# EMBEDDING_MODEL=text-embedding-3-small

# ===================
# Optional: Alternative LLM Providers
# ===================
# For Anthropic:
# LLM_PROVIDER=anthropic
# ANTHROPIC_API_KEY=your-anthropic-api-key

# For Azure OpenAI:
# LLM_PROVIDER=azure
# AZURE_OPENAI_API_KEY=your-azure-key
# AZURE_OPENAI_ENDPOINT=https://your-endpoint.openai.azure.com/

# For Ollama (local):
# LLM_PROVIDER=ollama
# LLM_MODEL=llama2
# LLM_API_BASE=http://localhost:11434

# ===================
# LangFuse Observability (Self-Hosted)
# ===================
# After starting LangFuse (docker compose up), go to http://localhost:3000
# 1. Create an account
# 2. Create a new project
# 3. Go to Settings > API Keys > Create new API key
# 4. Copy the keys below

MONITORING_TOOL=langfuse
LANGFUSE_SECRET_KEY=sk-lf-your-secret-key
LANGFUSE_PUBLIC_KEY=pk-lf-your-public-key
LANGFUSE_HOST=http://localhost:3000

# LangFuse Security (change these in production!)
LANGFUSE_SALT=cognee-langfuse-salt-change-me
LANGFUSE_ENCRYPTION_KEY=0000000000000000000000000000000000000000000000000000000000000000
LANGFUSE_NEXTAUTH_SECRET=cognee-langfuse-secret-change-me
